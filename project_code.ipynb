{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "7835f478",
      "metadata": {},
      "source": [
        "### Introduction\n",
        "- This notebook is the merged version of 5 seperate Jupyter Notebooks of our different experiments. We have merged them to submit the code in a cleaner way. Because of this and time reasons, we have not executed this notebook, as it contains training of models and many cloud operations. If requested, we could demonstrate the codes from the individual Jupyter Notebooks during the demo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "94556c00",
      "metadata": {
        "id": "94556c00"
      },
      "outputs": [],
      "source": [
        "pip install deepface"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5bc7ab61",
      "metadata": {
        "id": "5bc7ab61"
      },
      "outputs": [],
      "source": [
        "pip install ipykernel\n",
        "python -m ipykernel install --user --name=tf215 --display-name \"Python (tf215)\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "38d1270e",
      "metadata": {
        "id": "38d1270e"
      },
      "outputs": [],
      "source": [
        "pip install tf-keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3750982f",
      "metadata": {
        "id": "3750982f"
      },
      "outputs": [],
      "source": [
        "pip install tensorflow keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ac067064",
      "metadata": {
        "id": "ac067064"
      },
      "outputs": [],
      "source": [
        "pip install kafka-python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3a62bf53",
      "metadata": {
        "id": "3a62bf53"
      },
      "outputs": [],
      "source": [
        "# Importing libraries\n",
        "import azure\n",
        "import seaborn as sns\n",
        "import io\n",
        "import gc\n",
        "from azure.storage.blob import BlobClient, BlobServiceClient, ContainerClient\n",
        "from keras import utils\n",
        "from tensorflow.keras.utils import to_categorical, Sequence\n",
        "from tensorflow.keras import mixed_precision\n",
        "from IPython.core.display import display, HTML\n",
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "import base64\n",
        "import matplotlib.image as mpimg\n",
        "import plotly.express as px\n",
        "from plotly.offline import init_notebook_mode\n",
        "init_notebook_mode(connected=True)\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import os\n",
        "import time\n",
        "import pandas as pd\n",
        "import json\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "from deepface import DeepFace\n",
        "from io import StringIO\n",
        "import networkx as nx\n",
        "from kafka import KafkaProducer\n",
        "from scipy.spatial.distance import cosine\n",
        "from sklearn.metrics import f1_score\n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Dropout, Flatten, Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import load_model\n",
        "from collections import deque, defaultdict"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e333cc92",
      "metadata": {
        "id": "e333cc92"
      },
      "source": [
        "### Local Gender Detection Part"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2064d33a",
      "metadata": {
        "id": "2064d33a"
      },
      "outputs": [],
      "source": [
        "main_folder = 'C:/Users/90553/Desktop/bigdata kodlarÄ±/New folder/img_align_celeba/img_align_celeba/'\n",
        "images_folder = main_folder\n",
        "\n",
        "EXAMPLE_PIC = images_folder + '000001.jpg'\n",
        "\n",
        "TRAINING_SAMPLES = 10000\n",
        "VALIDATION_SAMPLES = 2000\n",
        "TEST_SAMPLES = 2000\n",
        "IMG_WIDTH = 178\n",
        "IMG_HEIGHT = 218\n",
        "BATCH_SIZE = 16\n",
        "NUM_EPOCHS = 20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "59ec3c7b",
      "metadata": {
        "id": "59ec3c7b"
      },
      "outputs": [],
      "source": [
        "df_attr = pd.read_csv('list_attr_celeba.csv')\n",
        "df_attr.set_index('image_id', inplace=True)\n",
        "df_attr.replace(to_replace=-1, value=0, inplace=True)\n",
        "df_attr.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "875d9ccd",
      "metadata": {
        "id": "875d9ccd"
      },
      "outputs": [],
      "source": [
        "# List of available attributes\n",
        "for i, j in enumerate(df_attr.columns):\n",
        "    print(i, j)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4e708363",
      "metadata": {
        "id": "4e708363"
      },
      "outputs": [],
      "source": [
        "# Displaying a sample image from the dataset\n",
        "img = load_img(EXAMPLE_PIC)\n",
        "plt.grid(False)\n",
        "plt.imshow(img)\n",
        "df_attr.loc[EXAMPLE_PIC.split('/')[-1]][['Attractive','Male','Young']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "054d871e",
      "metadata": {
        "id": "054d871e"
      },
      "outputs": [],
      "source": [
        "# Recommended partition\n",
        "df_partition = pd.read_csv('list_eval_partition.csv')\n",
        "df_partition.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dc633af9",
      "metadata": {
        "id": "dc633af9"
      },
      "outputs": [],
      "source": [
        "# Join the partition with the attributes\n",
        "df_partition.set_index('image_id', inplace=True)\n",
        "df_par_attr = df_partition.join(df_attr['Male'], how='inner')\n",
        "df_par_attr.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "277e7c79",
      "metadata": {
        "id": "277e7c79"
      },
      "outputs": [],
      "source": [
        "# Generate image generator for data augmentation\n",
        "datagen =  ImageDataGenerator(\n",
        "  #preprocessing_function=preprocess_input,\n",
        "  rotation_range=30,\n",
        "  width_shift_range=0.2,\n",
        "  height_shift_range=0.2,\n",
        "  shear_range=0.2,\n",
        "  zoom_range=0.2,\n",
        "  horizontal_flip=True\n",
        ")\n",
        "\n",
        "# Loading one image and reshaping it\n",
        "img = load_img(EXAMPLE_PIC)\n",
        "x = img_to_array(img)/255.\n",
        "x = x.reshape((1,) + x.shape)\n",
        "\n",
        "# Plotting 10 augmented images of the loaded image\n",
        "plt.figure(figsize=(20,10))\n",
        "plt.suptitle('Data Augmentation', fontsize=28)\n",
        "\n",
        "i = 0\n",
        "for batch in datagen.flow(x, batch_size=1):\n",
        "    plt.subplot(3, 5, i+1)\n",
        "    plt.grid(False)\n",
        "    plt.imshow( batch.reshape(218, 178, 3))\n",
        "\n",
        "    if i == 9:\n",
        "        break\n",
        "    i += 1\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "81cec42b",
      "metadata": {
        "id": "81cec42b"
      },
      "outputs": [],
      "source": [
        "# Train - Data Preparation - Data Augmentation with generators\n",
        "train_datagen =  ImageDataGenerator(\n",
        "  preprocessing_function=preprocess_input,\n",
        "  rotation_range=30,\n",
        "  width_shift_range=0.2,\n",
        "  height_shift_range=0.2,\n",
        "  shear_range=0.2,\n",
        "  zoom_range=0.2,\n",
        "  horizontal_flip=True,\n",
        ")\n",
        "\n",
        "df_train = df_par_attr[df_par_attr['partition'] == 0].reset_index()\n",
        "df_valid = df_par_attr[df_par_attr['partition'] == 1].reset_index()\n",
        "\n",
        "valid_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ba00e692",
      "metadata": {
        "id": "ba00e692"
      },
      "outputs": [],
      "source": [
        "df_train[\"Male\"] = df_train[\"Male\"].astype(str)\n",
        "df_valid[\"Male\"] = df_valid[\"Male\"].astype(str)\n",
        "\n",
        "train_generator = train_datagen.flow_from_dataframe(\n",
        "    dataframe=df_train,\n",
        "    directory=images_folder,\n",
        "    x_col=\"image_id\",\n",
        "    y_col=\"Male\",\n",
        "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode=\"categorical\"\n",
        ")\n",
        "\n",
        "valid_generator = valid_datagen.flow_from_dataframe(\n",
        "    dataframe=df_valid,\n",
        "    directory=images_folder,\n",
        "    x_col=\"image_id\",\n",
        "    y_col=\"Male\",\n",
        "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode=\"categorical\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8852589b",
      "metadata": {
        "id": "8852589b"
      },
      "outputs": [],
      "source": [
        "# Import InceptionV3 Model\n",
        "inc_model = InceptionV3(weights=None,\n",
        "                        include_top=False,\n",
        "                        input_shape=(IMG_HEIGHT, IMG_WIDTH, 3))\n",
        "\n",
        "print(\"number of layers:\", len(inc_model.layers))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d2f8acb4",
      "metadata": {
        "id": "d2f8acb4"
      },
      "outputs": [],
      "source": [
        "# Adding custom Layers\n",
        "x = inc_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(1024, activation=\"relu\")(x)\n",
        "x = Dropout(0.5)(x)\n",
        "x = Dense(512, activation=\"relu\")(x)\n",
        "predictions = Dense(2, activation=\"softmax\")(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5660b1ba",
      "metadata": {
        "id": "5660b1ba"
      },
      "outputs": [],
      "source": [
        "# Creating the final model\n",
        "model_ = Model(inputs=inc_model.input, outputs=predictions)\n",
        "\n",
        "# Freezing initial layers\n",
        "for layer in model_.layers[:52]:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Compiling the model\n",
        "model_.compile(optimizer=SGD(learning_rate=0.0001, momentum=0.9)\n",
        "                    , loss='categorical_crossentropy'\n",
        "                    , metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "54c51984",
      "metadata": {
        "id": "54c51984"
      },
      "outputs": [],
      "source": [
        "# Saving best weights into a file to reuse it later\n",
        "checkpointer = ModelCheckpoint(filepath='weights.best.inc.male.hdf5.keras',\n",
        "                               verbose=1, save_best_only=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "85121ab6",
      "metadata": {
        "id": "85121ab6"
      },
      "outputs": [],
      "source": [
        "# Running the model\n",
        "hist = model_.fit(\n",
        "    train_generator,\n",
        "    validation_data=valid_generator,\n",
        "    epochs=NUM_EPOCHS,\n",
        "    callbacks=[checkpointer],\n",
        "    verbose=1\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d4810757",
      "metadata": {
        "id": "d4810757"
      },
      "outputs": [],
      "source": [
        "# Displaying the train and validation accuracies\n",
        "# with respect to number of epochs the model trained\n",
        "plt.figure(figsize=(18, 4))\n",
        "plt.plot(hist.history['accuracy'], label = 'train')\n",
        "plt.plot(hist.history['val_accuracy'], label = 'valid')\n",
        "plt.legend()\n",
        "plt.title('Accuracy')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "386752c7",
      "metadata": {
        "id": "386752c7"
      },
      "outputs": [],
      "source": [
        "save_folder = r\"C:\\Users\\90553\\Desktop\\deneme\"\n",
        "os.makedirs(save_folder, exist_ok=True)\n",
        "\n",
        "attr_csv_path = r\"C:\\Users\\90553\\Desktop\\New folder (4)\\list_attr_celeba_with_reciprocal_friends_updated.csv\"\n",
        "df = pd.read_csv(attr_csv_path)\n",
        "\n",
        "start_id = 202600\n",
        "\n",
        "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
        "\n",
        "cap = cv2.VideoCapture(0)\n",
        "start_time = time.time()\n",
        "faces_detected = False\n",
        "faces_frame = None\n",
        "\n",
        "# Wait for a face to scan for 60 seconds\n",
        "while True:\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "    faces = face_cascade.detectMultiScale(gray, 1.1, 5)\n",
        "\n",
        "    if len(faces) >= 1:\n",
        "        faces_detected = True\n",
        "        faces_frame = (frame.copy(), faces)\n",
        "        break\n",
        "\n",
        "    if time.time() - start_time > 60:\n",
        "        print(\"No face detected within 60 seconds. Exiting...\")\n",
        "        break\n",
        "\n",
        "new_entries = []\n",
        "\n",
        "if faces_detected:\n",
        "    time.sleep(3)\n",
        "    img, faces = faces_frame\n",
        "    positions = []\n",
        "\n",
        "    if len(faces) == 1:\n",
        "        (x, y, w, h) = faces[0]\n",
        "        cropped_face = img[y:y+h, x:x+w]\n",
        "        filename = f\"{start_id}.jpg\"\n",
        "        save_path = os.path.join(save_folder, filename)\n",
        "        cv2.imwrite(save_path, cropped_face)\n",
        "\n",
        "        entry = {\n",
        "            'image_id': filename,\n",
        "            'friend1_id': pd.NA,\n",
        "            'friend2_id': pd.NA,\n",
        "            'Attractive': 0,\n",
        "            'Male': 0,\n",
        "            'Young': 0\n",
        "        }\n",
        "        new_entries.append(entry)\n",
        "        print(f\" One face saved: {filename}\")\n",
        "        start_id += 1\n",
        "\n",
        "    elif len(faces) >= 2:\n",
        "        for (x, y, w, h) in faces[:2]:  # First two face\n",
        "            cropped_face = img[y:y+h, x:x+w]\n",
        "            filename = f\"{start_id}.jpg\"\n",
        "            save_path = os.path.join(save_folder, filename)\n",
        "            cv2.imwrite(save_path, cropped_face)\n",
        "\n",
        "            entry = {\n",
        "                'image_id': filename,\n",
        "                'friend1_id': pd.NA,\n",
        "                'friend2_id': pd.NA,\n",
        "                'Attractive': 0,\n",
        "                'Male': 0,\n",
        "                'Young': 0\n",
        "            }\n",
        "            positions.append((x + w//2, y + h//2))\n",
        "            new_entries.append(entry)\n",
        "            print(f\" Face saved: {filename}\")\n",
        "            start_id += 1\n",
        "\n",
        "        # If the face captured is similar to a face that already\n",
        "        # exists in the dataset mark them as friends\n",
        "        dist = ((positions[0][0] - positions[1][0])**2 + (positions[0][1] - positions[1][1])**2)**0.5\n",
        "        if dist < 250:\n",
        "            new_entries[0]['friend1_id'] = new_entries[1]['image_id']\n",
        "            new_entries[1]['friend1_id'] = new_entries[0]['image_id']\n",
        "            print(\" Faces close to each other, assigned as friend1.\")\n",
        "\n",
        "cap.release()\n",
        "\n",
        "# Update the CSV file with the new face\n",
        "if new_entries:\n",
        "    df_new = pd.DataFrame(new_entries)\n",
        "    df = pd.concat([df, df_new], ignore_index=True)\n",
        "\n",
        "    save_csv_path = r\"C:\\Users\\90553\\Desktop\\New folder (4)\\list_attr_celeba_with_reciprocal_friends_updatedCameraChecked.csv\"\n",
        "    df.to_csv(save_csv_path, index=False)\n",
        "    print(f\" New face(s) saved and added to CSV file:\\n{save_csv_path}\")\n",
        "else:\n",
        "    print(\" No new faces added.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "98b2ad6e",
      "metadata": {
        "id": "98b2ad6e"
      },
      "outputs": [],
      "source": [
        "# Load the model with previously trained weights\n",
        "model_path = r\"C:\\Users\\90553\\Desktop\\bigdata kodlarÄ±\\weights.best.inc.male.hdf5.keras\"\n",
        "model_ = load_model(model_path)\n",
        "\n",
        "img_path = r\"C:\\Users\\90553\\Desktop\\deneme\\202600.jpg\"\n",
        "csv_path = r\"C:\\Users\\90553\\Desktop\\bigdata kodlarÄ±\\deneme\\list_attr_celeba_with_reciprocal_friends_new.csv\"\n",
        "output_path = csv_path.replace(\".csv\", \"_genderupdate.csv\")\n",
        "\n",
        "df = pd.read_csv(csv_path)\n",
        "\n",
        "img = load_img(img_path, target_size=(218, 178))\n",
        "x = img_to_array(img)\n",
        "x = np.expand_dims(x, axis=0)\n",
        "x = preprocess_input(x)\n",
        "\n",
        "prediction = model_.predict(x)\n",
        "predicted_class = np.argmax(prediction[0])\n",
        "\n",
        "image_id = os.path.basename(img_path)\n",
        "\n",
        "if image_id in df['image_id'].values:\n",
        "    df.loc[df['image_id'] == image_id, 'Male'] = predicted_class\n",
        "    df.to_csv(output_path, index=False)\n",
        "    print(f\"Updated 'Male' prediction for {image_id}: {predicted_class} (0: Female, 1: Male)\")\n",
        "    print(f\"Updated CSV file: {output_path}\")\n",
        "else:\n",
        "    print(f\"Error: {image_id} not found in CSV file.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "297c5dc9",
      "metadata": {
        "id": "297c5dc9"
      },
      "source": [
        "### Friendship Creation Part"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7e17776d",
      "metadata": {
        "id": "7e17776d"
      },
      "outputs": [],
      "source": [
        "# Loading the CSV\n",
        "df = pd.read_csv(\"list_attr_celeba_with_reciprocal_friends.csv\")\n",
        "\n",
        "# Shuffling the ids\n",
        "shuffled_ids = df['image_id'].dropna().sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "# Creating pairs\n",
        "min_len = len(shuffled_ids) // 2 * 2\n",
        "pairs = pd.DataFrame({\n",
        "    'A': shuffled_ids[:min_len:2].values,\n",
        "    'B': shuffled_ids[1:min_len:2].values\n",
        "})\n",
        "\n",
        "# Adding a new column to the dataframe\n",
        "df['friend2_id'] = None\n",
        "\n",
        "# Setting A's as the friends of B's\n",
        "df.loc[df['image_id'].isin(pairs['A']), 'friend2_id'] = df.loc[df['image_id'].isin(pairs['A'])]['image_id'].map(\n",
        "    dict(zip(pairs['A'], pairs['B']))\n",
        ")\n",
        "\n",
        "# Setting B's as the friends of A's\n",
        "df.loc[df['image_id'].isin(pairs['B']), 'friend2_id'] = df.loc[df['image_id'].isin(pairs['B'])]['image_id'].map(\n",
        "    dict(zip(pairs['B'], pairs['A']))\n",
        ")\n",
        "\n",
        "# Converting the dataframe to CSV\n",
        "df.to_csv(\"list_attr_celeba_with_reciprocal_friends_updated.csv\", index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6b29f5a8",
      "metadata": {
        "id": "6b29f5a8"
      },
      "source": [
        "### Advancing the Model\n",
        "- In this part we are advancing our model, which predicts the gender of a locally provided picture into a model, which extracts its data from an Azure Blob Container and makes a three output classification as Male-Goatee, Male-Nongoatee, and Female."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d832739d",
      "metadata": {
        "id": "d832739d"
      },
      "outputs": [],
      "source": [
        "blob = BlobClient(account_url=\"https://bigdatablobb.blob.core.windows.net\",\n",
        "                  container_name=\"data\",\n",
        "                  blob_name=\"archive (4)/list_attr_celeba.csv\",\n",
        "                  credential=\"iU/HWs1OoSAuD77pP8hMYYBojduyhEmC7qN7hMfYhrBst+AscQ1po2FTcjkg9k4OibGBTZxPAoeF+AStmiymSA==\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d6881126",
      "metadata": {
        "id": "d6881126"
      },
      "outputs": [],
      "source": [
        "stream = blob.download_blob().content_as_text()\n",
        "df_attr = pd.read_csv(io.StringIO(stream))\n",
        "df_attr.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "99ba8b4f",
      "metadata": {
        "id": "99ba8b4f"
      },
      "outputs": [],
      "source": [
        "df_attr.set_index('image_id', inplace=True)\n",
        "df_attr.replace(to_replace=-1, value=0, inplace=True) # replace -1 by 0\n",
        "df_attr.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "374985fe",
      "metadata": {
        "id": "374985fe"
      },
      "outputs": [],
      "source": [
        "blob = BlobClient(account_url=\"https://bigdatablobb.blob.core.windows.net\",\n",
        "                  container_name=\"data\",\n",
        "                  blob_name=\"archive (4)/list_eval_partition.csv\",\n",
        "                  credential=\"iU/HWs1OoSAuD77pP8hMYYBojduyhEmC7qN7hMfYhrBst+AscQ1po2FTcjkg9k4OibGBTZxPAoeF+AStmiymSA==\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7ac2e30d",
      "metadata": {
        "id": "7ac2e30d"
      },
      "outputs": [],
      "source": [
        "stream = blob.download_blob().content_as_text()\n",
        "df_partition = pd.read_csv(io.StringIO(stream))\n",
        "df_partition.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4e9466c6",
      "metadata": {
        "id": "4e9466c6"
      },
      "outputs": [],
      "source": [
        "# Join the partition with the attributes\n",
        "df_partition.set_index('image_id', inplace=True)\n",
        "df_partition_attr = df_partition.join(df_attr['Goatee'], how='inner')\n",
        "df_partition_attr.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "095c81aa",
      "metadata": {
        "id": "095c81aa"
      },
      "outputs": [],
      "source": [
        "# Azure blob setup\n",
        "connection_string = \"DefaultEndpointsProtocol=https;AccountName=bigdatablobb;AccountKey=enteryourkey\"\n",
        "container_name = \"data\"\n",
        "blob_service_client = BlobServiceClient.from_connection_string(connection_string)\n",
        "container_client = blob_service_client.get_container_client(container_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9a82cfd3",
      "metadata": {
        "id": "9a82cfd3"
      },
      "outputs": [],
      "source": [
        "TRAINING_SAMPLES = 10000\n",
        "VALIDATION_SAMPLES = 2000\n",
        "TEST_SAMPLES = 2000\n",
        "IMG_WIDTH = 178\n",
        "IMG_HEIGHT = 218\n",
        "BATCH_SIZE = 16\n",
        "NUM_EPOCHS = 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fef31fac",
      "metadata": {
        "id": "fef31fac"
      },
      "outputs": [],
      "source": [
        "# Path prefix inside Azure container\n",
        "blob_path_prefix = \"archive (4)/img_align_celeba/img_align_celeba/\"\n",
        "\n",
        "# # Function to load images from a blob container\n",
        "def load_reshape_image_from_blob(blob_path):\n",
        "    blob_client = container_client.get_blob_client(blob_path)\n",
        "    stream = blob_client.download_blob().readall()\n",
        "    image = Image.open(BytesIO(stream)).convert('RGB')\n",
        "    x = img_to_array(image) / 255.0\n",
        "    x = x.reshape((1,) + x.shape)\n",
        "    return x\n",
        "\n",
        "# Function to load images from a blob container with PIL\n",
        "def load_image_pil(blob_path):\n",
        "    blob_client = container_client.get_blob_client(blob_path)\n",
        "    stream = blob_client.download_blob().readall()\n",
        "    image = Image.open(BytesIO(stream)).convert('RGB')\n",
        "    return img_to_array(image) / 255.0\n",
        "\n",
        "# Function to load images from a blob container with CV2\n",
        "def load_image_cv2(blob_path):\n",
        "    blob_client = container_client.get_blob_client(blob_path)\n",
        "    stream = blob_client.download_blob().readall()\n",
        "    image_array = np.frombuffer(stream, np.uint8)\n",
        "    im = cv2.imdecode(image_array, cv2.IMREAD_COLOR)\n",
        "    im = cv2.resize(cv2.cvtColor(im, cv2.COLOR_BGR2RGB), (IMG_WIDTH, IMG_HEIGHT)).astype(np.float32) / 255.0\n",
        "    return im\n",
        "\n",
        "# Train-Test-Validation datasets generator according to partition value\n",
        "# with batching feature to prevent kernel crashing\n",
        "def dataset_generator(partition, attribute, num_samples, batch_size=256):\n",
        "    df_0 = df_partition_attr[(df_partition_attr['partition'] == partition) & (df_partition_attr[attribute] == 0)].sample(int(num_samples / 2))\n",
        "    df_1 = df_partition_attr[(df_partition_attr['partition'] == partition) & (df_partition_attr[attribute] == 1)].sample(int(num_samples / 2))\n",
        "    df_ = pd.concat([df_0, df_1])\n",
        "    df_[\"blob_path\"] = blob_path_prefix + df_.index.astype(str)\n",
        "\n",
        "    x_all = []\n",
        "    y_all = []\n",
        "\n",
        "    image_loader = load_image_pil if partition != 2 else load_image_cv2\n",
        "\n",
        "    # Batch processing\n",
        "    for i in tqdm(range(0, len(df_), batch_size), desc=\"Batch loading\"):\n",
        "        batch_df = df_.iloc[i:i + batch_size]\n",
        "        x_batch = [image_loader(path) for path in batch_df[\"blob_path\"]]\n",
        "        x_batch = np.stack(x_batch, axis=0)\n",
        "        y_batch = to_categorical(batch_df[attribute], 2)\n",
        "\n",
        "        x_all.append(x_batch)\n",
        "        y_all.append(y_batch)\n",
        "\n",
        "    # Concatenate all batches\n",
        "    x_ = np.concatenate(x_all, axis=0)\n",
        "    y_ = np.concatenate(y_all, axis=0)\n",
        "\n",
        "    return x_, y_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3e2be6ba",
      "metadata": {
        "id": "3e2be6ba"
      },
      "outputs": [],
      "source": [
        "class AzureImageDataGenerator(Sequence):\n",
        "    def __init__(self, dataframe, blob_path_prefix, container_client, x_col, y_col,\n",
        "                 batch_size, target_size, preprocess_fn=None, augmenter=None, shuffle=True):\n",
        "        self.df = dataframe.reset_index(drop=True)\n",
        "        self.blob_path_prefix = blob_path_prefix\n",
        "        self.container_client = container_client\n",
        "        self.x_col = x_col\n",
        "        self.y_col = y_col\n",
        "        self.batch_size = batch_size\n",
        "        self.target_size = target_size\n",
        "        self.preprocess_fn = preprocess_fn\n",
        "        self.augmenter = augmenter\n",
        "        self.shuffle = shuffle\n",
        "        self.num_classes = len(self.df[y_col].unique())\n",
        "        self.on_epoch_end()\n",
        "\n",
        "    def __len__(self):\n",
        "        return int(np.ceil(len(self.df) / self.batch_size))\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        if self.shuffle:\n",
        "            self.df = self.df.sample(frac=1).reset_index(drop=True)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        batch_df = self.df.iloc[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
        "        images = []\n",
        "        labels = []\n",
        "\n",
        "        for _, row in batch_df.iterrows():\n",
        "            blob_path = self.blob_path_prefix + row[self.x_col]\n",
        "            blob_client = self.container_client.get_blob_client(blob_path)\n",
        "            stream = blob_client.download_blob().readall()\n",
        "            img = Image.open(BytesIO(stream)).convert('RGB')\n",
        "            img = img.resize(self.target_size)\n",
        "            img_array = np.array(img).astype(np.float32)\n",
        "\n",
        "            if self.preprocess_fn:\n",
        "                img_array = self.preprocess_fn(img_array)\n",
        "\n",
        "            images.append(img_array)\n",
        "            labels.append(row[self.y_col])\n",
        "\n",
        "        x = np.stack(images, axis=0)\n",
        "        y = to_categorical(labels, num_classes=self.num_classes)\n",
        "\n",
        "        if self.augmenter:\n",
        "            x, y = next(self.augmenter.flow(x, y, batch_size=self.batch_size, shuffle=False))\n",
        "\n",
        "        return x, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f6366926",
      "metadata": {
        "id": "f6366926"
      },
      "outputs": [],
      "source": [
        "df_train = df_partition_attr[df_partition_attr['partition'] == 0].reset_index()\n",
        "df_valid = df_partition_attr[df_partition_attr['partition'] == 1].reset_index()\n",
        "df_train[\"Goatee\"] = df_train[\"Goatee\"].astype(int)\n",
        "df_valid[\"Goatee\"] = df_valid[\"Goatee\"].astype(int)\n",
        "\n",
        "# Azure-based generator for train\n",
        "train_datagen = ImageDataGenerator(\n",
        "    preprocessing_function=preprocess_input,\n",
        "    rotation_range=30,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        ")\n",
        "\n",
        "# Custom Azure generator\n",
        "train_generator = AzureImageDataGenerator(\n",
        "    dataframe=df_train,\n",
        "    blob_path_prefix=\"archive (4)/img_align_celeba/img_align_celeba/\",\n",
        "    container_client=container_client,\n",
        "    x_col=\"image_id\",\n",
        "    y_col=\"Goatee\",\n",
        "    batch_size=8,\n",
        "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "    preprocess_fn=None,\n",
        "    augmenter=train_datagen,\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "valid_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
        "\n",
        "# Azure-based generator for validation\n",
        "valid_generator = AzureImageDataGenerator(\n",
        "    dataframe=df_valid,\n",
        "    blob_path_prefix=\"archive (4)/img_align_celeba/img_align_celeba/\",\n",
        "    container_client=container_client,\n",
        "    x_col=\"image_id\",\n",
        "    y_col=\"Goatee\",\n",
        "    batch_size=8,\n",
        "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "    preprocess_fn=None,\n",
        "    augmenter=valid_datagen,\n",
        "    shuffle=False\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "578f88df",
      "metadata": {
        "id": "578f88df"
      },
      "outputs": [],
      "source": [
        "# Loading InceptionV3\n",
        "base_model = InceptionV3(weights = 'imagenet', include_top = False)\n",
        "\n",
        "# Freezing layers in the base model to prevent overfitting\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Adding new layers\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(512, activation = 'relu')(x)\n",
        "predictions = Dense(2, activation = 'softmax')(x)\n",
        "\n",
        "# Defining final model\n",
        "model = Model(inputs = base_model.input, outputs = predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ad62ffe4",
      "metadata": {
        "id": "ad62ffe4"
      },
      "outputs": [],
      "source": [
        "# Compiling model (this time with a different optimizer)\n",
        "model.compile(optimizer = 'rmsprop',\n",
        "              loss = 'categorical_crossentropy',\n",
        "              metrics = ['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "82ada35c",
      "metadata": {
        "id": "82ada35c"
      },
      "outputs": [],
      "source": [
        "# Precaution to prevent kernel crash\n",
        "tf.config.optimizer.set_jit(True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ae49ddab",
      "metadata": {
        "id": "ae49ddab"
      },
      "outputs": [],
      "source": [
        "# Precaution to prevent kernel crash\n",
        "mixed_precision.set_global_policy('mixed_float16')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2da57619",
      "metadata": {
        "id": "2da57619"
      },
      "outputs": [],
      "source": [
        "# Storing the best weights to reuse later\n",
        "checkpoint = ModelCheckpoint(\n",
        "    filepath=\"weights.best.inc.goatee.hdf5.keras\",\n",
        "    monitor=\"val_loss\",\n",
        "    verbose=1,\n",
        "    save_best_only=True,\n",
        "    mode=\"min\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "10d77f60",
      "metadata": {
        "id": "10d77f60"
      },
      "outputs": [],
      "source": [
        "# Running the model\n",
        "model.fit(\n",
        "    train_generator,\n",
        "    validation_data=valid_generator,\n",
        "    epochs=4,\n",
        "    callbacks=[checkpoint]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "BMeOPx3-YD7p",
      "metadata": {
        "id": "BMeOPx3-YD7p"
      },
      "outputs": [],
      "source": [
        "# We are obtaining embedded vector using deepface for all photos\n",
        "\n",
        "image_folder = r\"C:\\Users\\90553\\Desktop\\bigdata kodlari\\New folder\\img_align_celeba\\img_align_celeba\"\n",
        "csv_path = os.path.join(image_folder, \"embeddings_until_202599.csv\")\n",
        "\n",
        "start_id = 1\n",
        "end_id = 202599\n",
        "\n",
        "embedding_entries = []\n",
        "\n",
        "for image_id in tqdm(range(start_id, end_id + 1)):\n",
        "    filename = f\"{image_id:06d}.jpg\"\n",
        "    full_path = os.path.join(image_folder, filename)\n",
        "\n",
        "    if not os.path.exists(full_path):\n",
        "        print(f\"File not found: {filename}\")\n",
        "        continue\n",
        "\n",
        "    try:\n",
        "        result = DeepFace.represent(img_path=full_path, model_name=\"VGG-Face\", enforce_detection=False)[0]\n",
        "        embedding_vector = result[\"embedding\"]\n",
        "    except Exception as e:\n",
        "        embedding_vector = []\n",
        "        print(f\"Failed to get embedding: {filename} -> {e}\")\n",
        "\n",
        "    embedding_entries.append({\n",
        "        \"image_id\": filename,\n",
        "        \"embedding\": json.dumps(embedding_vector)\n",
        "    })\n",
        "\n",
        "df_embeddings = pd.DataFrame(embedding_entries)\n",
        "df_embeddings.to_csv(csv_path, index=False)\n",
        "print(f\"All embeddings saved to {csv_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "JeafiBZ1YGhW",
      "metadata": {
        "id": "JeafiBZ1YGhW"
      },
      "outputs": [],
      "source": [
        "# We are adding embeddings to our own database\n",
        "embedding_csv = r\"C:\\Users\\90553\\Desktop\\bigdata kodlari\\New folder\\img_align_celeba\\img_align_celeba\\embeddings_until_202599.csv\"\n",
        "main_csv = r\"C:\\Users\\90553\\Desktop\\New folder (4)\\list_attr_celeba_with_reciprocal_friends_updatedCameraChecked.csv\"\n",
        "output_csv = r\"C:\\Users\\90553\\Desktop\\New folder (4)\\list_attr_celeba_with_reciprocal_friends_final.csv\"\n",
        "\n",
        "df_embeddings = pd.read_csv(embedding_csv)\n",
        "df_main = pd.read_csv(main_csv)\n",
        "\n",
        "df_result = df_main.merge(df_embeddings, on=\"image_id\", how=\"left\")\n",
        "\n",
        "df_result.to_csv(output_csv, index=False)\n",
        "print(f\"Embedding column added and CSV successfully saved:\\n{output_csv}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5e9621bb",
      "metadata": {
        "id": "5e9621bb"
      },
      "source": [
        "### Adding Kafka and Writing the Friendship Tree to the Cloud"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "22d88750",
      "metadata": {
        "id": "22d88750"
      },
      "outputs": [],
      "source": [
        "# Azure connection\n",
        "connection_string = \"DefaultEndpointsProtocol=https;AccountName=bigdatablobb;AccountKey=enteryourkey\"\n",
        "blob_service_client = BlobServiceClient.from_connection_string(connection_string)\n",
        "container_client = blob_service_client.get_container_client(\"data\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f360c1c4",
      "metadata": {
        "id": "f360c1c4"
      },
      "outputs": [],
      "source": [
        "# Uploading CSV file to blob container function\n",
        "def upload_blob_csv(df, blob_name):\n",
        "    buffer = io.StringIO()\n",
        "    df.to_csv(buffer, index=False)\n",
        "    buffer.seek(0)\n",
        "    container_client.upload_blob(name=blob_name, data=buffer.getvalue(), overwrite=True)\n",
        "    print(f\" Loaded: {blob_name}\")\n",
        "\n",
        "df = pd.read_csv(r\"C:\\Users\\90553\\Desktop\\New folder (4)\\list_attr_celeba_with_reciprocal_friends_final.csv\")\n",
        "df.replace(-1, 0, inplace=True)\n",
        "\n",
        "# Filter the files and upload them to blob container\n",
        "upload_blob_csv(df[(df['Male'] == 1) & (df['Goatee'] == 1)], \"filtered_data/goatee_males.csv\")\n",
        "upload_blob_csv(df[(df['Male'] == 1) & (df['Goatee'] == 0)], \"filtered_data/nongoatee_males.csv\")\n",
        "upload_blob_csv(df[df['Male'] == 0], \"filtered_data/females.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "33087e55",
      "metadata": {
        "id": "33087e55"
      },
      "outputs": [],
      "source": [
        "# Loading the CSV file with friendship columns\n",
        "local_csv_path = r\"C:\\Users\\90553\\Downloads\\list_attr_celeba_with_reciprocal_friends_updated.csv\"\n",
        "df = pd.read_csv(local_csv_path)\n",
        "\n",
        "# Uploading the dataframe to the blob container as a new CSV file\n",
        "upload_blob_csv(df, \"filtered_data/full_attributes.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "adb2a6a0",
      "metadata": {
        "id": "adb2a6a0"
      },
      "outputs": [],
      "source": [
        "local_csv_path = r\"C:\\Users\\90553\\Downloads\\list_attr_celeba_with_reciprocal_friends_updated.csv\"\n",
        "df = pd.read_csv(local_csv_path)\n",
        "\n",
        "# Replacing -1 values (if any) with 0's\n",
        "df.replace(-1, 0, inplace=True)\n",
        "\n",
        "# Uploading the dataframe to the blob container as a new CSV file\n",
        "upload_blob_csv(df, \"filtered_data/full_attributes.csv\")\n",
        "\n",
        "# Uploading three seperate CSV files (Male-Goatee, Male-Nongoatee, and Female) to the blob container\n",
        "upload_blob_csv(df[(df['Male'] == 1) & (df['Goatee'] == 1)], \"filtered_data/Lightgoatee_males.csv\")\n",
        "upload_blob_csv(df[(df['Male'] == 1) & (df['Goatee'] == 0)], \"filtered_data/Lightnongoatee_males.csv\")\n",
        "upload_blob_csv(df[df['Male'] == 0], \"filtered_data/Lightfemales.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "00f7ccca",
      "metadata": {
        "id": "00f7ccca"
      },
      "outputs": [],
      "source": [
        "connection_string = \"DefaultEndpointsProtocol=https;AccountName=bigdatablobb;AccountKey=enteryourkey\"\n",
        "container_name = \"data\"\n",
        "blob_service_client = BlobServiceClient.from_connection_string(connection_string)\n",
        "container_client = blob_service_client.get_container_client(container_name)\n",
        "\n",
        "# Reading the CSV file locally and setting a similarity threshold\n",
        "local_csv_path = r\"C:\\Users\\90553\\Desktop\\New folder (4)\\list_attr_celeba_with_reciprocal_friends_final.csv\"\n",
        "similarity_threshold = 0.80\n",
        "\n",
        "def cosine_similarity(vec1, vec2):\n",
        "    return 1 - cosine(vec1, vec2)\n",
        "\n",
        "def parse_embedding(embedding_str):\n",
        "    if pd.isna(embedding_str) or not isinstance(embedding_str, str):\n",
        "        raise ValueError(\"embedding is empty, NaN or invalid.\")\n",
        "    return np.array(json.loads(embedding_str))\n",
        "\n",
        "def download_blob_csv_streaming(blob_path, chunksize=300):\n",
        "    blob_client = container_client.get_blob_client(blob_path)\n",
        "    stream = blob_client.download_blob().chunks()\n",
        "    buffer = \"\"\n",
        "    header = None\n",
        "\n",
        "    for chunk in stream:\n",
        "        decoded = chunk.decode(\"utf-8\")\n",
        "        buffer += decoded\n",
        "        lines = buffer.split(\"\\n\")\n",
        "\n",
        "        if header is None:\n",
        "            header = lines[0]\n",
        "            lines = lines[1:]\n",
        "\n",
        "        while len(lines) >= chunksize:\n",
        "            chunk_data = \"\\n\".join(lines[:chunksize])\n",
        "            lines = lines[chunksize:]\n",
        "            yield pd.read_csv(StringIO(header + \"\\n\" + chunk_data))\n",
        "\n",
        "        buffer = \"\\n\".join(lines)\n",
        "\n",
        "    if buffer.strip():\n",
        "        yield pd.read_csv(StringIO(header + \"\\n\" + buffer.strip()))\n",
        "\n",
        "def generate_90_percent_similar_vector(original_vector, noise_factor=0.05):\n",
        "    array = np.array(original_vector)\n",
        "    vector_length = len(array)\n",
        "    num_to_modify = int(0.1 * vector_length)\n",
        "    indices_to_modify = random.sample(range(vector_length), num_to_modify)\n",
        "\n",
        "    modified_array = np.copy(array)\n",
        "    for idx in indices_to_modify:\n",
        "        noise = np.random.uniform(-noise_factor, noise_factor)\n",
        "        modified_array[idx] += noise\n",
        "\n",
        "    modified_array = np.clip(modified_array, 0, None)\n",
        "    print(\" A vector with 90% similarity was successfully produced.\")\n",
        "    return modified_array.tolist()\n",
        "\n",
        "def classify_person(row):\n",
        "    if row.get('gender') == 'Female':\n",
        "        return 'Woman'\n",
        "    elif row.get('beard') == 1:\n",
        "        return 'Bearded Man'\n",
        "    else:\n",
        "        return 'Beardless Man'\n",
        "\n",
        "def find_best_match_streaming(input_embedding, chunk_iter):\n",
        "    for chunk in chunk_iter:\n",
        "        if 'embedding_y' not in chunk.columns:\n",
        "            print(\" Warning: Column 'embedding_y' not found, chunk skipped.\")\n",
        "            continue\n",
        "\n",
        "        for _, row in chunk.iterrows():\n",
        "            embedding_raw = row.get('embedding_y')\n",
        "            current_id = row.get('id') or row.get('image_id', 'unknown')\n",
        "\n",
        "            if pd.isna(embedding_raw) or not isinstance(embedding_raw, str):\n",
        "                print(f\" Line skipped: invalid embedding (ID: {current_id})\")\n",
        "                continue\n",
        "\n",
        "            try:\n",
        "                emb = parse_embedding(embedding_raw)\n",
        "                score = cosine_similarity(input_embedding, emb)\n",
        "                print(f\" Comparing to '{current_id}'... Similarity score: {round(score, 4)}\")\n",
        "                if score >= similarity_threshold:\n",
        "                    print(f\" Similarity threshold passed! Matching ID: {current_id}\")\n",
        "                    return row, score\n",
        "            except Exception as e:\n",
        "                print(f\" The row could not be processed (ID: {current_id}): {e}\")\n",
        "    return None, None\n",
        "\n",
        "# Reading the embeddings\n",
        "df_first_row = pd.read_csv(local_csv_path, usecols=[\"embedding_y\"], nrows=1)\n",
        "original_vector = json.loads(df_first_row.loc[0, \"embedding_y\"])\n",
        "\n",
        "# Generate 90 percent similar vectors\n",
        "modified_vector = generate_90_percent_similar_vector(original_vector)\n",
        "\n",
        "datasets = [\n",
        "    \"filtered_data/females.csv\",\n",
        "    \"filtered_data/goatee_males.csv\",\n",
        "    \"filtered_data/nongoatee_males.csv\"\n",
        "]\n",
        "\n",
        "# Searching the CSV files for a match\n",
        "for path in datasets:\n",
        "    print(f\"\\n Inside '{path}' searching piece by piece...\")\n",
        "    chunk_iter = download_blob_csv_streaming(path)\n",
        "    match_row, match_score = find_best_match_streaming(modified_vector, chunk_iter)\n",
        "    if match_row is not None:\n",
        "        result = {\n",
        "            \"id\": match_row.get(\"id\") or match_row.get(\"image_id\", \"unknown\"),\n",
        "            \"similarity\": round(match_score, 4),\n",
        "            \"type\": classify_person(match_row)\n",
        "        }\n",
        "        print(\"\\n First match, which is higher than %80, is found:\")\n",
        "        print(json.dumps(result, indent=2))\n",
        "        break\n",
        "else:\n",
        "    print(\"\\n No match was found to be over 80%.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "48917725",
      "metadata": {
        "id": "48917725"
      },
      "outputs": [],
      "source": [
        "save_folder = r\"C:\\Users\\90553\\Desktop\\deneme\"\n",
        "os.makedirs(save_folder, exist_ok=True)\n",
        "\n",
        "similarity_threshold = 0.80\n",
        "friend_id = \"202600.jpg\"\n",
        "\n",
        "connection_string = \"DefaultEndpointsProtocol=https;AccountName=bigdatablobb;AccountKey=enteryourkey\"\n",
        "container_name = \"data\"\n",
        "blob_service_client = BlobServiceClient.from_connection_string(connection_string)\n",
        "container_client = blob_service_client.get_container_client(container_name)\n",
        "\n",
        "\n",
        "def download_blob_csv(blob_name):\n",
        "    blob_client = container_client.get_blob_client(blob_name)\n",
        "    content = blob_client.download_blob().readall().decode(\"utf-8\")\n",
        "    return pd.read_csv(StringIO(content))\n",
        "\n",
        "def cosine_similarity_custom(vec1, vec2):\n",
        "    return 1 - cosine(vec1, vec2)\n",
        "\n",
        "def parse_embedding(embedding_str):\n",
        "    if pd.isna(embedding_str) or not isinstance(embedding_str, str):\n",
        "        raise ValueError(\"Invalid embedding data.\")\n",
        "    return np.array(json.loads(embedding_str))\n",
        "\n",
        "def classify_person(row):\n",
        "    if row.get('Male') == 0:\n",
        "        return 'Woman'\n",
        "    elif row.get('Goatee', 0) == 1:\n",
        "        return 'Bearded Man'\n",
        "    else:\n",
        "        return 'Beardless Man'\n",
        "\n",
        "def smart_range_search_indices(total_length, center_index, window_size=100, step=10):\n",
        "    yield_range = []\n",
        "    for offset in range(0, window_size + 1, step):\n",
        "        lower_start = max(center_index - (offset + step), 0)\n",
        "        lower_end = max(center_index - offset, 0)\n",
        "        upper_start = min(center_index + offset + 1, total_length)\n",
        "        upper_end = min(center_index + offset + step + 1, total_length)\n",
        "        if upper_start < upper_end:\n",
        "            yield_range.append((upper_start, upper_end))\n",
        "        if lower_start < lower_end:\n",
        "            yield_range.append((lower_start, lower_end))\n",
        "    return yield_range\n",
        "\n",
        "def find_embedding_column(df):\n",
        "    for col in df.columns:\n",
        "        if 'embedding' in col.lower():\n",
        "            return col\n",
        "    return None\n",
        "\n",
        "def guided_search_middle_smart(input_embedding, df, friend_id, similarity_threshold=0.80):\n",
        "    embedding_col = find_embedding_column(df)\n",
        "    if not embedding_col:\n",
        "        print(\" Embedding column not found.\")\n",
        "        return None\n",
        "\n",
        "    df = df.sort_values(by='image_id').reset_index(drop=True)\n",
        "    id_list = df['image_id'].tolist()\n",
        "\n",
        "    try:\n",
        "        friend_index = id_list.index(friend_id)\n",
        "    except ValueError:\n",
        "        print(f\" Friend ID {friend_id} not found. Starting from the middle.\")\n",
        "        friend_index = len(df) // 2\n",
        "\n",
        "    position_ratio = friend_index / len(df)\n",
        "\n",
        "    if position_ratio < 0.33:\n",
        "        indices = range(0, len(df))\n",
        "    elif position_ratio > 0.66:\n",
        "        indices = range(len(df) - 1, -1, -1)\n",
        "    else:\n",
        "        indices = []\n",
        "        for start, end in smart_range_search_indices(len(df), friend_index):\n",
        "            indices.extend(range(start, end))\n",
        "\n",
        "    for i in indices:\n",
        "        row = df.loc[i]\n",
        "        embedding_raw = row.get(embedding_col)\n",
        "        current_id = row.get(\"image_id\", f\"row_{i}\")\n",
        "        if pd.isna(embedding_raw) or not isinstance(embedding_raw, str):\n",
        "            print(f\" Row skipped (ID: {current_id}) - Invalid embedding\")\n",
        "            continue\n",
        "        try:\n",
        "            emb = parse_embedding(embedding_raw)\n",
        "            score = cosine_similarity_custom(input_embedding, emb)\n",
        "            print(f\" Compared with '{current_id}'... Score: {round(score, 4)}\")\n",
        "            if score >= similarity_threshold:\n",
        "                result = {\n",
        "                    \"id\": current_id,\n",
        "                    \"similarity\": round(score, 4),\n",
        "                    \"type\": classify_person(row)\n",
        "                }\n",
        "                print(\"\\n Match found:\")\n",
        "                print(json.dumps(result, indent=2))\n",
        "                return result\n",
        "        except Exception as e:\n",
        "            print(f\" Could not be processed (ID: {current_id}): {e}\")\n",
        "\n",
        "    print(\" Could not find a match.\")\n",
        "    return None\n",
        "\n",
        "# Download the datasets from the blob container\n",
        "df_female = download_blob_csv(\"filtered_data/females.csv\")\n",
        "df_goatee = download_blob_csv(\"filtered_data/goatee_males.csv\")\n",
        "df_nongoatee = download_blob_csv(\"filtered_data/nongoatee_males.csv\")\n",
        "\n",
        "# Random embedding input\n",
        "input_embedding = np.random.rand(128)\n",
        "\n",
        "dfs = [df_female, df_goatee, df_nongoatee]\n",
        "final_result = None\n",
        "\n",
        "# Search the dataframes for a friend match\n",
        "for df in dfs:\n",
        "    result = guided_search_middle_smart(input_embedding, df, friend_id)\n",
        "    if result is not None:\n",
        "        final_result = result\n",
        "        break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "807f0ede",
      "metadata": {
        "id": "807f0ede"
      },
      "outputs": [],
      "source": [
        "connection_string = \"DefaultEndpointsProtocol=https;AccountName=bigdatablobb;AccountKey=enteryourkey\"\n",
        "container_name = \"data\"\n",
        "blob_service_client = BlobServiceClient.from_connection_string(connection_string)\n",
        "container_client = blob_service_client.get_container_client(container_name)\n",
        "\n",
        "# Reading the CSV (which includes the friendship relations) on the blob container to a dataframe\n",
        "def download_full_attributes_csv():\n",
        "    blob_client = container_client.get_blob_client(\"filtered_data/full_attributes.csv\")\n",
        "    content = blob_client.download_blob().readall().decode(\"utf-8\")\n",
        "    df = pd.read_csv(StringIO(content))\n",
        "    df['image_id'] = df['image_id'].astype(str)\n",
        "    df['friend1_id'] = df['friend1_id'].astype(str)\n",
        "    df['friend2_id'] = df['friend2_id'].astype(str)\n",
        "    return df\n",
        "\n",
        "# Friendship tree building function\n",
        "def build_friendship_tree(df, root_id, max_depth=1):\n",
        "    tree = defaultdict(list)\n",
        "    visited = set()\n",
        "    queue = deque([(root_id, 0)])\n",
        "\n",
        "    while queue:\n",
        "        current_id, depth = queue.popleft()\n",
        "        if depth > max_depth or current_id in visited:\n",
        "            continue\n",
        "\n",
        "        visited.add(current_id)\n",
        "        row = df[df['image_id'] == current_id]\n",
        "        if row.empty:\n",
        "            continue\n",
        "\n",
        "        friend1 = row.iloc[0].get('friend1_id')\n",
        "        friend2 = row.iloc[0].get('friend2_id')\n",
        "        for friend in [friend1, friend2]:\n",
        "            if pd.notna(friend) and friend not in visited:\n",
        "                tree[current_id].append(friend)\n",
        "                queue.append((friend, depth + 1))\n",
        "\n",
        "    return dict(tree)\n",
        "\n",
        "# Generating a friendship tree for the image \"000003.jpg\"\n",
        "df_full = download_full_attributes_csv()\n",
        "root_id = \"000003.jpg\"\n",
        "tree = build_friendship_tree(df_full, root_id=root_id)\n",
        "\n",
        "# Printing the friends\n",
        "print(f\"\\n Friendship Tree for Root ID: {root_id}\")\n",
        "print(json.dumps(tree, indent=2))\n",
        "\n",
        "print(\"\\n File used: filtered_data/full_attributes.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "83b6d761",
      "metadata": {
        "id": "83b6d761"
      },
      "outputs": [],
      "source": [
        "# Function to send the friendship tree to Kafka\n",
        "def send_tree_to_kafka(tree_dict, topic_name=\"friendship-trees\", bootstrap_servers=\"13.48.25.92:9092\"):\n",
        "    producer = KafkaProducer(\n",
        "        bootstrap_servers=[bootstrap_servers],\n",
        "        value_serializer=lambda v: json.dumps(v).encode('utf-8')\n",
        "    )\n",
        "    producer.send(topic_name, tree_dict)\n",
        "    producer.flush()\n",
        "    print(f\" Tree data was sent to Kafka topic '{topic_name}' .\")\n",
        "\n",
        "# Function for drawing friendship tree\n",
        "def visualize_friendship_tree(tree_dict, title=\"Friendship Tree\"):\n",
        "    G = nx.DiGraph()\n",
        "    for parent, children in tree_dict.items():\n",
        "        for child in children:\n",
        "            G.add_edge(parent, child)\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    pos = nx.spring_layout(G, seed=42)\n",
        "    nx.draw(G, pos, with_labels=True, node_color='skyblue', node_size=2000,\n",
        "            font_size=10, font_weight='bold', arrows=True)\n",
        "    plt.title(title)\n",
        "    plt.show()\n",
        "\n",
        "send_tree_to_kafka(tree)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "33a92058",
      "metadata": {
        "id": "33a92058"
      },
      "source": [
        "### Reading Face Input From Camera and Storing Writing Them to the Cloud"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "31de6f2a",
      "metadata": {
        "id": "31de6f2a"
      },
      "outputs": [],
      "source": [
        "# Loading the previously trained weights\n",
        "gender_model_path = \"weights.best.inc.male.hdf5.keras\"\n",
        "gender_model = load_model(gender_model_path, compile=False)\n",
        "\n",
        "goatee_model_path = \"weights.best.inc.goatee.hdf5.keras\"\n",
        "goatee_model = load_model(goatee_model_path, compile=False)\n",
        "\n",
        "# Save them in .h5 format\n",
        "gender_model.save(\"weights.best.inc.male.h5\")\n",
        "goatee_model.save(\"weights.best.inc.goatee.h5\")\n",
        "\n",
        "print(\" Both models were converted to .h5 format.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "392e5521",
      "metadata": {
        "id": "392e5521"
      },
      "outputs": [],
      "source": [
        "connection_string = \"DefaultEndpointsProtocol=https;AccountName=bigdatablobb;AccountKey=enteryourkey\"\n",
        "container_name = \"data\"\n",
        "blob_service_client = BlobServiceClient.from_connection_string(connection_string)\n",
        "container_client = blob_service_client.get_container_client(container_name)\n",
        "\n",
        "start_id = 202600\n",
        "\n",
        "\n",
        "def upload_to_blob(df, blob_name):\n",
        "    csv_buffer = StringIO()\n",
        "    df.to_csv(csv_buffer, index=False)\n",
        "    blob_client = container_client.get_blob_client(blob_name)\n",
        "    blob_client.upload_blob(csv_buffer.getvalue(), overwrite=True)\n",
        "    print(f\" '{blob_name}' is uploaded successfully.\")\n",
        "\n",
        "def download_blob_csv(blob_name):\n",
        "    blob_client = container_client.get_blob_client(blob_name)\n",
        "    content = blob_client.download_blob().readall().decode(\"utf-8\")\n",
        "    return pd.read_csv(StringIO(content))\n",
        "\n",
        "def predict_gender_from_array(img_array):\n",
        "    img_array = np.expand_dims(img_array, axis=0)\n",
        "    img_array = preprocess_input(img_array)\n",
        "    prediction = gender_model.predict(img_array)\n",
        "    return int(np.argmax(prediction))\n",
        "\n",
        "def predict_goatee_from_array(img_array):\n",
        "    img_array = np.expand_dims(img_array, axis=0)\n",
        "    img_array = preprocess_input(img_array)\n",
        "    prediction = goatee_model.predict(img_array)\n",
        "    return int(np.argmax(prediction))\n",
        "\n",
        "# Loading the models\n",
        "gender_model = load_model(\"weights.best.inc.male.h5\", compile=False)\n",
        "goatee_model = load_model(\"weights.best.inc.goatee.h5\", compile=False)\n",
        "\n",
        "# Face detection with device camera\n",
        "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
        "cap = cv2.VideoCapture(0)\n",
        "start_time = time.time()\n",
        "faces_detected = False\n",
        "faces_frame = None\n",
        "\n",
        "while True:\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "    faces = face_cascade.detectMultiScale(gray, 1.1, 5)\n",
        "    if len(faces) >= 1:\n",
        "        faces_detected = True\n",
        "        faces_frame = (frame.copy(), faces)\n",
        "        break\n",
        "    if time.time() - start_time > 60:\n",
        "        print(\" No face detected within 60 seconds. Exiting...\")\n",
        "        break\n",
        "\n",
        "new_entries = []\n",
        "\n",
        "if faces_detected:\n",
        "    time.sleep(3)\n",
        "    img, faces = faces_frame\n",
        "\n",
        "    for i, (x, y, w, h) in enumerate(faces[:2]):\n",
        "        cropped_face = img[y:y+h, x:x+w]\n",
        "        filename = f\"{start_id}.jpg\"\n",
        "\n",
        "        pil_face = Image.fromarray(cv2.cvtColor(cropped_face, cv2.COLOR_BGR2RGB)).resize((178, 218))\n",
        "        gender_input = img_to_array(pil_face)\n",
        "        predicted_gender = predict_gender_from_array(gender_input)\n",
        "\n",
        "        embedding_vector = []\n",
        "        try:\n",
        "            pil_face.save(f\"temp_{filename}\")\n",
        "            result = DeepFace.represent(img_path=f\"temp_{filename}\", model_name=\"VGG-Face\", enforce_detection=False)[0]\n",
        "            os.remove(f\"temp_{filename}\")\n",
        "            embedding_vector = result[\"embedding\"]\n",
        "        except Exception as e:\n",
        "            print(f\" Embedding failed: {filename} -> {e}\")\n",
        "\n",
        "        entry = {\n",
        "            'image_id': filename,\n",
        "            'friend1_id': pd.NA,\n",
        "            'friend2_id': pd.NA,\n",
        "            'Attractive': 0,\n",
        "            'Male': predicted_gender,\n",
        "            'Young': 0,\n",
        "            'embedding': json.dumps(embedding_vector)\n",
        "        }\n",
        "\n",
        "        new_entries.append(entry)\n",
        "        print(f\" {filename} processed | Gender: {'Male' if predicted_gender else 'Female'}\")\n",
        "        start_id += 1\n",
        "\n",
        "cap.release()\n",
        "\n",
        "# Downloading the light (in terms of file size) CSV files from the blob container\n",
        "df_female = download_blob_csv(\"filtered_data/Lightfemales.csv\")\n",
        "df_goatee = download_blob_csv(\"filtered_data/Lightgoatee_males.csv\")\n",
        "df_nongoatee = download_blob_csv(\"filtered_data/Lightnongoatee_males.csv\")\n",
        "\n",
        "# Writing the new face to the related CSV files on the blob container\n",
        "# according to its property of being Male-Goatee, Male-Nongoatee, or Female\n",
        "if new_entries:\n",
        "    for entry in new_entries:\n",
        "        pil_face = Image.fromarray(cv2.cvtColor(cropped_face, cv2.COLOR_BGR2RGB)).resize((178, 218))\n",
        "        buffer = BytesIO()\n",
        "        pil_face.save(buffer, format=\"JPEG\")\n",
        "        image_blob_client = container_client.get_blob_client(f\"images/{entry['image_id']}\")\n",
        "        image_blob_client.upload_blob(buffer.getvalue(), overwrite=True)\n",
        "\n",
        "        if entry['Male'] == 0:\n",
        "            df_female = pd.concat([df_female, pd.DataFrame([entry])], ignore_index=True)\n",
        "            upload_to_blob(df_female, \"filtered_data/Lightfemales.csv\")\n",
        "\n",
        "        elif entry['Male'] == 1:\n",
        "            goatee_label = predict_goatee_from_array(gender_input)\n",
        "            if goatee_label == 1:\n",
        "                df_goatee = pd.concat([df_goatee, pd.DataFrame([entry])], ignore_index=True)\n",
        "                upload_to_blob(df_goatee, \"filtered_data/Lightgoatee_males.csv\")\n",
        "                print(f\" {entry['image_id']} is added as a man with goatee.\")\n",
        "            else:\n",
        "                df_nongoatee = pd.concat([df_nongoatee, pd.DataFrame([entry])], ignore_index=True)\n",
        "                upload_to_blob(df_nongoatee, \"filtered_data/Lightnongoatee_males.csv\")\n",
        "                print(f\" {entry['image_id']} is added as a man with no goatee.\")\n",
        "else:\n",
        "    print(\" No new faces added.\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
